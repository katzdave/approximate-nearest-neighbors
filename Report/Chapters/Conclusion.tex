\chapter{Conclusion} % Main chapter title

\label{conclusion} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 5. \emph{Conclusion}} % This is for the header on each page - perhaps a 

\section{Future Work}

Future work can be divided into two main components: heuristic testing/tuning, and real world implementation.

\subsection{Heuristic Tuning}

While it was demonstrated that the heuristics used provided significant performance improvements over a standard k-d tree, they are likely not the optimal heuristics for every dataset.  One way to improve performance would be tune split heuristics specific to the distribution of a dataset.  For example, for a dataset with a uniform distribution across all dimensions, spatial median splitting will perform very well.  However, for a dataset which consists of distinct Gaussian distributed clusters, an alternative heuristic could lead to large perfomance improvements.  In general, more complicated heuristics such as surface area heuristics have demonstrated improved performance with a higher offline computational cost \citep{hunt2006fast}.  If these heuristics were adapted to the constraint of DRVs further improvements in the quality of the result set given a fixed number of searches could likely be made.  Tuning this heuristic would effect the theoretical best case scenario when the seed and query DRVs match.

Another route for potential improvement is to improve the tree selection heuristic.  In the current implementation, a distance metric is used to provide a scalar value which represents the quality of a tree.  However, another potential approach would be to keep track of how well a seed DRV matches a query DRV in all dimensions.  This would mean using a vector based district metric rather than a scalar.  In doing so, rather than simply using the trees which best match the DRV overall, a set of trees could be extracted which attempt to make sure each dimension, especially the ones with highest relevance, are represented with a high amount of splits in at least some of the trees.  In doing so performance when searching the set of selected trees could likely be improved.

\subsection{Real World Considerations}

There are a variety of aspects which much be considered when attempting a real world of this algorithm.  The first is the large memory cost.  As shown in the section \ref{results}, a larger amount of trees results in improved performance, as the overall quality of the top trees will be higher.  However, there is a diminishing return to this effect, so memory consumption should be balanced, and tuned.  One proposed method of tuning is to develop a cost metric which considers both memory, and the quality of results.  Using a small initial set of requested or randomly generated queries, one can use this data to minimize this cost metric, and select the optimal memory consumption.  Other algorithmic parameters can be tuned in a similar manner.  By examining the performance relative to a linear search on a subset of queries, one can attempt these queries with different parameters to see if performance changes.  \citep{muja_flann_2009} suggests some methods for automatic parameter selection such as putting weights on different cost aspects of the algorithm.

If the dataset is large, a single server implementation is likely not possible as the memory consumption of this algorithm can be hundreds of times larger than the original dataset.  To counteract this, we propose a distributed approach with N trees split across M compute nodes, with some duplication factor D.  The duplication factor represents, the number of different nodes in which a single tree exists in memory on.  A larger duplication factor will further increase memory cost by D times, but will allow the system to be more robust in the event of a node's failure.  \citep{nitzberg1991distributed} discusses many types of potential architectures for a system with distrubed memory, and considerations of each.  Load balancing is another important consideration, which attempts to provide work to the least busy nodes \citep{cybenko1989dynamic}.

In our suggested distributed implementation, each node will store as many trees as it can fit into memory, and will also store the seed DRVs used to construct each tree, and the nodes which hold each of these trees.  A load balancer should be applied to determine which nodes requests come through to.  When a request arrives at a node, that node can compute the best set of trees to search, and the least busy nodes which holds those trees.  This selection process can be augmented by adding an additional cost to trees whose nodes are currently busy.

After the top trees and their nodes are selected for a query, a distributed priority and hashtable must be used.  Considerations for these data structures are discussed in \citep{kaashoek2003koorde} and \citep{rogers1995supporting}.  It is also important to ensure that the searches happen in relative parallel for best results.  For example, if one node searches its allocated amount before another, results will not be as accurate as if the searches are interleaved between the two nodes.  In our testbed, searches were perfectly interleaved relative to the quality of each tree.  Thus, real world results will likely not reach these benchmarks.

Another important consideration with this distributed system is future performance tuning.  In our proposed construction of the data structure, no information was available about the frequencies of different DRVs in each query, and as such a uniform distribution of seed DRVs was used.  However, by storing all requested DRVs, one can learn which type of queries are most popular.  The system can then eliminate the trees which are least used, and replace them with trees which better match the popular queries.  This dynamic adjustment will allow the system's performance to improve over time as more data about the types of searches performed is gathered.

Lastly, one must consider performance on a changing dataset.  In particular, datasets tend to grow over time and as such it is important to support efficient insertion of new data.  To insert a new item, it must be added to every single k-d tree.  As mentioned in section \ref{sec:kdmod}, the insertion of a new element into a k-d tree is O(Log(N)).  However, over time trees are likely to become unbalanced, and the quality of results from performance will begin to degrade.  Thus, this would be an imporant effect to benchmark in order to determine how quickly performance degrades.  After doing so, one approach of avoiding the issue would be to constantly rebuild trees.  This could be performed one tree at a time, so the system could remain live while upgrade its data structures in the background.  When this cost is introduced however the offline construction cost of trees becomes more imporant.  Thus for a constantly growing data structure there may be some value in the random splitting heuristic.