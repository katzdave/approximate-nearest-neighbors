\chapter{Introduction} % Main chapter title

\label{futurework} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a 

Nearest neighbor search (NNS) on a vector space, described formally in Section \ref{sec:overview} has a variety of applications including... The most basic algorithm for NNS, a linear search is described in Section \ref{sec:linear}.  Unfortunitely, for large datasets upon which many NNS queries are being performed, a linear search will take too much time.  Approximate nearest neighbor (ANN) algorithms address this concern by creating an index which allows computation of a result set in sublinear time as described in Section \ref{sec:ann}. While this result set is not guaranteed to be perfectly accurate, this limitation does not prevent ANN algorithms from being used for most NNS applications.

One challenge with modeling a data set in a vector space, is that the distance between two points, using one of the distance metrics described in Section \ref{sec:overview} should represent the similarity of two items in the data set.  As such, before performing an ANN query each dimension needs to be normalized proportional to its importance.  For, different queries however blah...

Thus, our goal was to design an index which can efficiently compute ANNs on queries that specify the relevance of each dimension.  To do so, we developed an system which generates a large set of indexes optimized for different dimension weights, and efficiently selects the best set of indexes at query time.  The particular index our system is based upon is the k-d tree.  This index is described in detail in Section \ref{sec:kdtree} and reasons for its selection in our system are described in Section \ref{sec:kdtreemotiv}.

To evaluate our system, we tested its performance against that of a conventional k-d tree, and a k-d optimized for the transformed vector space (which represents a theorestic best case performance of our heuristics described in Section \ref{section:splitdim} but cannot be constructed efficiently at query time).  Our result quality metric described in Section \ref{sec:inittest} measures the amount the average distance of points in the result set increased compared to a linear search.  Our system was then benchmarked on multiple datasets and with different types of ANN queries.  Results are shown in Chapter \ref{results}